{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (DecisionTree.ipynb)\n",
    "\n",
    "Train a Decision Tree using a ChoiceMaker to decide when to stop branching.\n",
    "\n",
    "Goal: See how a ChoiceMaker performs when applied to a novel area. Having the lowest error \n",
    "compared to naive methods would be great.\n",
    "\n",
    "Comparison: We compare against a naive way of making a decision tree algorithm\n",
    "private, as well as another method described in a sketchy paper. I implemented\n",
    "everything.\n",
    "\n",
    "Current Results: The Choicemaker seems to be competitive with the two other methods\n",
    "sometimes. We definitely need more data supporting this claim for a final submission.\n",
    "\n",
    "Improvement 1: figure out a way to make epsilon equal to 1.0 always.\n",
    "Improvement 2: simplify the error computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import DPrivacy as dp\n",
    "from ChoiceMaker import DTChoice\n",
    "from sklearn import model_selection, feature_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decision_tree import CoefCM, Leaf, Split, DB, DBMetas, PDTree\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrain flags!\n",
    "rerun_gen_training_data = True\n",
    "rerun_train_cms = True\n",
    "rerun_exps = [True, True, True, True, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_algs = {'leaf': Leaf(), 'split': Split()}\n",
    "\"\"\"\n",
    "\n",
    "This competitor algorithm appears in:\n",
    "\n",
    "Sam Fletcher and Md Zahidul Islam. Decision Tree Classification with Differential Privacy: A Survey.\n",
    "In CoRR, volume = abs/1611.01919, 2016\n",
    "\n",
    "This algorithm was chosen because it is \"subsumed\" by Jostle, meaning its code can be represented internally\n",
    "by Jostle's trees.\n",
    "\"\"\"\n",
    "fried_cm = CoefCM([1, 0, 1, 0, -1, 0, -1], np.log(1.414))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pickle.load(open('decision_tree_data/adult.pkl', 'rb'))\n",
    "\n",
    "nurs = pd.read_csv('../datasets/nursery.data', header=None)\n",
    "nurs = nurs.apply(lambda x: x.astype('category'))\n",
    "\n",
    "default = pickle.load(open('decision_tree_data/default.pkl', 'rb'))\n",
    "\n",
    "loan = pd.read_csv('../datasets/student-loan.csv')\n",
    "loan = loan.apply(lambda x: x.astype('category'))\n",
    "\n",
    "lending = pickle.load(open('decision_tree_data/lending.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 9, 10, 16, 16, 7, 15, 6, 5, 2, 2, 2, 4, 5, 2]\n",
      "[3, 5, 4, 4, 3, 2, 3, 3, 5]\n",
      "[10, 2, 7, 4, 7, 11, 11, 11, 11, 10, 10, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2]\n",
      "[10, 2, 2, 8, 7, 16, 2, 2, 2]\n",
      "[2, 4, 4, 6, 8, 6, 10, 10, 5, 2, 3, 7, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "print([len(adult[c].cat.categories) for c in adult])\n",
    "print([len(nurs[c].cat.categories) for c in nurs])\n",
    "print([len(default[c].cat.categories) for c in default])\n",
    "print([len(loan[c].cat.categories) for c in loan])\n",
    "print([len(lending[c].cat.categories) for c in lending])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class null_cm:\n",
    "    def __init__(self):\n",
    "        self.leaf = Leaf()\n",
    "        self.split = Split()\n",
    "    def choose(self, db):\n",
    "        if db.depth < db.max_depth:\n",
    "            return self.split.run(db)\n",
    "        else:\n",
    "            return self.leaf.run(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performs dataset surgery on a seed_db. Parameters such as target number of rows are fixed here, \n",
    "which makes sense because seed databases are roughly the same size in this experiment.\n",
    "\n",
    "Parameters:\n",
    "seed_db: dataset to slice up\n",
    "eps: value of epsilon for the experiments\n",
    "prng: random number generator\n",
    "returns a tuple: (regret of algorithm on each db, metafeatures associated with db, and the db itself)\n",
    "\"\"\"\n",
    "def get_train_dbs(seed_db, eps, prng):\n",
    "    regs = []\n",
    "    X = []\n",
    "    D = []\n",
    "    for l in range(1, 4): #Used to be 6\n",
    "        for x in range(2**(l+3)):\n",
    "            cols = prng.permutation(seed_db.columns[:-1])\n",
    "            db_groups = seed_db.groupby(list(cols[:l])).groups\n",
    "            idxs = db_groups[list(db_groups)[prng.randint(len(db_groups))]]\n",
    "            L = idxs.size\n",
    "            L = min(L, 5000)\n",
    "            L = prng.randint(0.7*L, L)\n",
    "            idxs = prng.choice(idxs, L)\n",
    "            data = DB(seed_db.loc[idxs, cols[l:]], seed_db.loc[idxs, seed_db.columns[-1]], None, None, epsilon=eps, depth=l)\n",
    "            regs.append({name: alg.error(data) for name, alg in tree_algs.items()})\n",
    "            X.append(DBMetas()(data))\n",
    "            D.append(data)\n",
    "    #Large DBs    \n",
    "    for x in range(16):\n",
    "        cols = seed_db.columns[:-1]\n",
    "        L = len(seed_db)\n",
    "        L = min(L, 5000)\n",
    "        L = prng.randint(0.7*L, L)\n",
    "        new_db = seed_db.sample(L, random_state=prng)\n",
    "        data = DB(new_db.loc[:, cols], new_db.loc[:, seed_db.columns[-1]], None, None, epsilon=eps, depth=0)\n",
    "        regs.append({name: alg.error(data) for name, alg in tree_algs.items()})\n",
    "        X.append(DBMetas()(data))\n",
    "        D.append(data)\n",
    "    return (regs, X, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Does a similar thing as get_train_dbs, but makes fewer slices, and the slices are large\n",
    "because these are databases we want to test on (and we probably won't be using tiny dbs in real life).\n",
    "\"\"\"\n",
    "\n",
    "def get_test_dbs(seed_db, eps, prng):\n",
    "    cols = seed_db.columns[:-1]\n",
    "    y_col = seed_db.columns[-1]\n",
    "    L = len(seed_db)\n",
    "    L = min(L, int(5000/0.7))\n",
    "    L = prng.randint(0.7*L, L)\n",
    "    new_db = seed_db.sample(L, random_state=prng).reset_index(drop=True)\n",
    "    split = int(0.7*L)\n",
    "    md = min(len(cols), 4)\n",
    "    d = DB(new_db.loc[:split, cols], new_db.loc[:split, y_col], \\\n",
    "           new_db.loc[split:, cols], new_db.loc[split:, y_col], epsilon=eps, max_depth=md)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#directory = '/longterm/jimola/data_train.pkl'\n",
    "#directory = 'decision_tree_metadata/training_dbs.pkl'\n",
    "if rerun_gen_training_data:\n",
    "    prng=np.random.RandomState(12345)\n",
    "    eps_vals = np.array([0.05, 0.1, 0.25, 0.5, 0.8])\n",
    "    def get_test(db, prng):\n",
    "        dbs = []\n",
    "        for i in range(0, 3):\n",
    "            for e in eps_vals:\n",
    "                dbs.append(get_train_dbs(db, e, prng))\n",
    "        return dbs\n",
    "    data_train = [get_test(db, prng) for db in \\\n",
    "                  [nurs, default, loan, adult, lending]]\n",
    "    pickle.dump(data_train, open(directory, 'wb'))\n",
    "else:\n",
    "    #These dbs take up a ton of memory. They are not on the github repo but they are in a directory on Matt's machine\n",
    "    data_train = pickle.load(open(directory, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains a choicemaker\n",
    "\n",
    "Parameters:\n",
    "info: list of (regrets, metafeatures, db) tuples. \n",
    "            db is actually not needed; could just be a metafeature list.\n",
    "\"\"\"\n",
    "def get_cm(info):\n",
    "    regrets, X, datas = zip(*info)\n",
    "    regrets = pd.concat([pd.DataFrame(r) for r in regrets], ignore_index=True)\n",
    "    X = pd.concat([pd.DataFrame(r) for r in X], ignore_index=True)\n",
    "    return DTChoice(X, DBMetas(), tree_algs, regrets=regrets)\n",
    "\n",
    "if rerun_train_cms:\n",
    "    cms = [get_cm(o) for o in data_train]\n",
    "    mfs = [cm.X for cm in cms]\n",
    "    regs = [cm.regrets for cm in cms]\n",
    "    pickle.dump(mfs, open('decision_tree_metadata/data.pkl', 'wb'))\n",
    "    pickle.dump(regs, open('decision_tree_metadata/regrets.pkl', 'wb'))\n",
    "else:\n",
    "    mfs = pickle.load(open('decision_tree_metadata/data.pkl', 'rb'))\n",
    "    regs = pickle.load(open('decision_tree_metadata/regrets.pkl', 'rb'))\n",
    "    cms = [ DTChoice(mfs[i], DBMetas(), tree_algs, regrets=regs[i]) for i in range(len(mfs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A convenience method for taking training data in choicemakers and combining it into one choicemaker.\n",
    "Used in my experiments for leave-one-out cross validation.\n",
    "\n",
    "Parameters:\n",
    "cms: list of choicemakers.\n",
    "C, msl: parameters of the choicemaker's internal tree, but not super important as they can be set later.\n",
    "\"\"\"\n",
    "def combine_cms(cms, C=0, msl=1):\n",
    "    Xs = pd.concat([cm.X for cm in cms], ignore_index=True)\n",
    "    regs = pd.concat([cm.regrets for cm in cms], ignore_index=True)\n",
    "    dt = DTChoice(Xs, DBMetas(), tree_algs, regrets=regs, C=0)\n",
    "    dt.model = DecisionTreeClassifier(min_samples_leaf=msl, max_depth=3)\n",
    "    dt.retrain_model()\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tests a set of choicemakers on a test of databases and returns % classified correctly.\n",
    "Parameters:\n",
    "cm_list: list of choicemakers.\n",
    "dbs: list of test dbs.\n",
    "\"\"\"\n",
    "def get_results(dbs, cm_list):\n",
    "    budgets = [x.epsilon for x in dbs]\n",
    "    ans = []\n",
    "    for cm in cm_list:\n",
    "        dt = PDTree()\n",
    "        L = []\n",
    "        for t in dbs:\n",
    "            L.append( dt.fit_and_predict(t, cm) )\n",
    "            #print(dt.leaf.numruns)\n",
    "        for i in range(len(dbs)):\n",
    "            dbs[i].epsilon = budgets[i]\n",
    "        M = np.array([(L[i] == dbs[i].y_test).sum() / len(dbs[i].y_test) for i in range(len(dbs))])\n",
    "        ans.append(M)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reinitialize prng before the experiments so we can reproduce their exact runs\n",
    "prng = np.random.RandomState(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Format for the experiments:\n",
    "outsample_cm{i} is the choicemaker for all databases from which the test database are not generated, \n",
    "        a sort of leave-one-out cross-validation.\n",
    "insample_cm{i} is the complement of big_cm{i}, so the same database is used for both training and\n",
    "        testing data. This is to serve as a comparison.\n",
    "I set the depth of the internal tree to 4,\n",
    "    and min. samples per leaf (see sklearn documentation) to 10, somewhat arbitrarily.\n",
    "I test using epsilon=0.25 and run 5 trials for each experiment on each database. This could certainly be increased\n",
    "as the error bars have high noise.\n",
    "\"\"\"\n",
    "epsilon = 0.25\n",
    "num_trials = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(i, db, msl=10, md=4):\n",
    "    insample_cm = cms[i]\n",
    "    insample_cm.model = DecisionTreeClassifier(min_samples_leaf=msl, max_depth=md)\n",
    "    insample_cm.retrain_model()\n",
    "    outsample_cm = combine_cms(cms[:i] + cms[(i+1):])\n",
    "    outsample_cm.model = DecisionTreeClassifier(min_samples_leaf=msl, max_depth=md)\n",
    "    outsample_cm.retrain_model()\n",
    "    if rerun_exps[i]:\n",
    "        res = get_results(db, [null_cm(), outsample_cm, insample_cm, fried_cm])\n",
    "        pickle.dump(res, open('decision_tree_results/experiment%d.pkl' % i, 'wb'))\n",
    "    else:\n",
    "        res = pickle.load(open('decision_tree_results/experiment%d.pkl' % i, 'rb'))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nursdata = [get_test_dbs(nurs, epsilon, prng) for x in range(0, num_trials)]\n",
    "res0 = run_experiment(0, nursdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.37308086,  0.3987055 ,  0.42545983,  0.43457944,  0.42050439,\n",
       "         0.3768595 ,  0.38921283,  0.42380478,  0.39817792,  0.40098765,\n",
       "         0.26568502,  0.35394214,  0.3298153 ,  0.46357227,  0.44303797,\n",
       "         0.4673031 ,  0.3591954 ,  0.32620993,  0.39292929,  0.42603211]),\n",
       " array([ 0.22620266,  0.5223301 ,  0.51016457,  0.52476636,  0.53179825,\n",
       "         0.52286501,  0.52526725,  0.52689243,  0.53376206,  0.52641975,\n",
       "         0.52752881,  0.5377198 ,  0.53891821,  0.53877791,  0.50886076,\n",
       "         0.5150358 ,  0.51436782,  0.49654305,  0.52222222,  0.50745413]),\n",
       " array([ 0.53991812,  0.46860841,  0.54743466,  0.53504673,  0.50822368,\n",
       "         0.48099174,  0.50048591,  0.55129482,  0.51018221,  0.5417284 ,\n",
       "         0.47823303,  0.55473625,  0.40897098,  0.64571093,  0.47594937,\n",
       "         0.45680191,  0.5335249 ,  0.45757385,  0.53989899,  0.5309633 ]),\n",
       " array([ 0.66376663,  0.52686084,  0.5750242 ,  0.6364486 ,  0.58223684,\n",
       "         0.39338843,  0.52526725,  0.48007968,  0.48177921,  0.53925926,\n",
       "         0.59411012,  0.63471356,  0.57189974,  0.52820212,  0.4835443 ,\n",
       "         0.54319809,  0.58429119,  0.46385921,  0.57222222,  0.4891055 ])]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem 1: why is there so much variance between runs?\n",
    "res0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_recom     0.333333\n",
       "priority      0.329167\n",
       "spec_prior    0.312037\n",
       "very_recom    0.025309\n",
       "recommend     0.000154\n",
       "Name: 8, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(nurs[8]) / len(nurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defaultsdata = [get_test_dbs(default, epsilon, prng) for i in range(0, num_trials)]\n",
    "res1 = run_experiment(1, defaultsdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.69086886,  0.78467951,  0.78019716,  0.76467237])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(res1)).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.67580568,  0.69516539,  0.68174297,  0.69070668,  0.70114943,\n",
       "         0.66034381,  0.67734554,  0.68646865,  0.72531328,  0.66272888,\n",
       "         0.66350711,  0.70960699,  0.71164418,  0.7373494 ,  0.678242  ,\n",
       "         0.71533613,  0.70899149,  0.68947113,  0.70389761,  0.64256076]),\n",
       " array([ 0.81385281,  0.7562341 ,  0.78599007,  0.79186834,  0.78947368,\n",
       "         0.77296977,  0.7791762 ,  0.76369637,  0.78546366,  0.77731837,\n",
       "         0.77843602,  0.77729258,  0.78610695,  0.78024096,  0.78350515,\n",
       "         0.76785714,  0.80801944,  0.78990781,  0.79290285,  0.81327801]),\n",
       " array([ 0.77008177,  0.78422392,  0.78599007,  0.79186834,  0.78947368,\n",
       "         0.76704209,  0.7791762 ,  0.76633663,  0.77744361,  0.77790904,\n",
       "         0.77843602,  0.78820961,  0.78610695,  0.78554217,  0.77428106,\n",
       "         0.76785714,  0.79343864,  0.78117419,  0.79290285,  0.76644932]),\n",
       " array([ 0.70899471,  0.7913486 ,  0.76833977,  0.7821878 ,  0.79370841,\n",
       "         0.73147599,  0.79004577,  0.74719472,  0.76741855,  0.79208506,\n",
       "         0.74526066,  0.76310044,  0.76911544,  0.77108434,  0.77373847,\n",
       "         0.75682773,  0.7855407 ,  0.76564774,  0.74403723,  0.7462952 ])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7788\n",
       "1    0.2212\n",
       "Name: default payment next month, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(default['default payment next month']) / len(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbtest = defaultsdata[0]\n",
    "dbtest.epsilon = 100\n",
    "dt = PDTree()\n",
    "results = dt.fit_and_predict(dbtest, null_cm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78787878787878785"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results == dbtest.y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "loandata = [get_test_dbs(loan, epsilon, prng) for i in range(num_trials)]\n",
    "res2 = run_experiment(2, loandata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.902\n",
       "1    0.098\n",
       "Name: unemployed, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oh no!\n",
    "pd.value_counts(loan.unemployed) / len(loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61167286,  0.85971109,  0.90030092,  0.90030092])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res2).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adultdata = [get_test_dbs(adult, epsilon, prng) for i in range(num_trials)]\n",
    "res3 = run_experiment(3, adultdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " <=50K    0.75919\n",
       " >50K     0.24081\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem 2. Why is naive doing worse?? Why can't we do any better?\n",
    "pd.value_counts(adult.TARGET) / len(adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.76392573,  0.7026466 ,  0.62422803,  0.6773411 ,  0.70975731,\n",
       "         0.65783133,  0.63305322,  0.6747541 ,  0.63845675,  0.62565445,\n",
       "         0.68501171,  0.71948301,  0.6432958 ,  0.65813424,  0.66578774,\n",
       "         0.70659722,  0.67582697,  0.62891114,  0.71374587,  0.67219917]),\n",
       " array([ 0.75490716,  0.76543851,  0.76579572,  0.75788452,  0.74640911,\n",
       "         0.75277108,  0.75536881,  0.75016393,  0.76851276,  0.74502618,\n",
       "         0.76229508,  0.75825754,  0.7395087 ,  0.76564278,  0.74555043,\n",
       "         0.75925926,  0.74300254,  0.76470588,  0.76712329,  0.76089212]),\n",
       " array([ 0.75490716,  0.76543851,  0.78004751,  0.75739932,  0.74640911,\n",
       "         0.75277108,  0.75536881,  0.75016393,  0.76851276,  0.74502618,\n",
       "         0.76229508,  0.75825754,  0.7395087 ,  0.76564278,  0.74555043,\n",
       "         0.75925926,  0.74300254,  0.76470588,  0.78318375,  0.76089212]),\n",
       " array([ 0.71724138,  0.76388168,  0.70593824,  0.76564774,  0.76077266,\n",
       "         0.79614458,  0.77917834,  0.79540984,  0.75917859,  0.78429319,\n",
       "         0.76288056,  0.77549067,  0.73183214,  0.77246871,  0.80290046,\n",
       "         0.75173611,  0.75165394,  0.79411765,  0.79310345,  0.77489627])]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.67383207,  0.75642577,  0.75791712,  0.76693831])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res3).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(db, cm, epsilon,D=4):\n",
    "    testdb = copy.deepcopy(db)\n",
    "    testdb_train = copy.deepcopy(db)\n",
    "    testdb.max_depth=D\n",
    "    testdb_train.max_depth=D\n",
    "    testdb_train.X_test = testdb_train.X\n",
    "    testdb_train.y_test = testdb_train.y\n",
    "    testdb.epsilon = 1.0\n",
    "    testdb_train.epsilon = 1.0\n",
    "    dt = PDTree()\n",
    "    P_out = dt.fit_and_predict(testdb, null_cm())\n",
    "    P_in = dt.fit_and_predict(testdb_train, null_cm())\n",
    "    M_out = (P_out == testdb.y_test).mean()\n",
    "    M_in = (P_in == testdb_train.y_test).mean()\n",
    "    return (M_in, M_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80236524903343187, 0.79681697612732094)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug(adultdata[0], null_cm, 100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lendingdata = [get_test_dbs(lending, epsilon, prng) for x in range(num_trials)]\n",
    "res4 = run_experiment(4, lendingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.60280253,  0.82704829,  0.82636571,  0.82192822])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res4).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.783405\n",
       "1    0.214499\n",
       "9    0.001324\n",
       "8    0.000772\n",
       "Name: social_security, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(lending.social_security) / len(lending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E = np.array([res0,res1,res2,res3,res4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#E[dataset][algorithm][trial]\n",
    "stds = E.std(axis=2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = 1.0-E.mean(axis=2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'green', 'orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches = [mpatches.Patch(color=c) for c in colors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axis = plt.subplots()\n",
    "axis.set_xticks([0,1,2,3])\n",
    "axis.set_xticklabels(['Naive','Jostle\\n,In Sample','Jostle,\\nOut of Sample','Competitor\\nAlgorithm'])\n",
    "axis.set_xlabel('Algorithm')\n",
    "axis.set_ylabel('Mean Error')\n",
    "#axis.legend(handles=patches, labels=['Alg1', 'Alg2', 'Jostle'])\n",
    "axis.set_title('Mean Performance for 3 Stopping Criteria')\n",
    "axis.bar(range(4), errors, color=colors, yerr=stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
