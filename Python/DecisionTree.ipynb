{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (DecisionTree.ipynb)\n",
    "Train a Decision Tree classifier, selecting a rule for when it is time to stop branching to\n",
    "avoid overfitting.\n",
    "\n",
    "Goal: See how a ChoiceMaker performs when applied to a novel area. Having the lowest error \n",
    "compared to naive methods would be great.\n",
    "\n",
    "Comparison: We compare against a naive way of making a decision tree algorithm\n",
    "private, as well as another method described in a sketchy paper. I implemented\n",
    "everything.\n",
    "\n",
    "Current Results: The Choicemaker seems to be competitive with the two other methods\n",
    "sometimes. We definitely need more data supporting this claim for a final submission.\n",
    "\n",
    "Improvement 1: figure out a way to make epsilon equal to 1.0 always.\n",
    "Improvement 2: simplify the error computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DPrivacy as dp\n",
    "from ChoiceMaker import DTChoice\n",
    "from sklearn import model_selection, feature_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decision_tree import CoefCM, Leaf, Split, DB, DBMetas, PDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrain flags!\n",
    "rerun_gen_training_data = False\n",
    "rerun_train_cms = False\n",
    "rerun_exps = [False, False, True, True, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_algs = {'leaf': Leaf(), 'split': Split()}\n",
    "fried_cm = CoefCM([1, 0, 1, 0, -1, 0, -1], np.log(1.414))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pickle.load(open('decision_tree_data/adult.pkl', 'rb'))\n",
    "\n",
    "nurs = pd.read_csv('../datasets/nursery.data', header=None)\n",
    "nurs = nurs.apply(lambda x: x.astype('category'))\n",
    "\n",
    "default = pickle.load(open('decision_tree_data/default.pkl', 'rb'))\n",
    "\n",
    "loan = pd.read_csv('../datasets/student-loan.csv')\n",
    "loan = loan.apply(lambda x: x.astype('category'))\n",
    "\n",
    "lending = pickle.load(open('decision_tree_data/lending.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class null_cm:\n",
    "    def __init__(self):\n",
    "        self.leaf = Leaf()\n",
    "        self.split = Split()\n",
    "    def choose(self, db):\n",
    "        if db.depth < db.max_depth:\n",
    "            return self.split.run(db)\n",
    "        else:\n",
    "            return self.leaf.run(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performs dataset surgery on a seed_db. Parameters such as target number of rows are fixed here, \n",
    "makes sense because seed databases are roughly the same size in this experiment.\n",
    "\n",
    "Parameters:\n",
    "seed_db: dataset on which to slice up\n",
    "eps: value of epsilon for the experiments\n",
    "prng: random number generator\n",
    "returns a tuple: (regret of algorithm on each db, metafeatures associated with db, and the db itself)\n",
    "\"\"\"\n",
    "def get_train_dbs(seed_db, eps, prng):\n",
    "    regs = []\n",
    "    X = []\n",
    "    D = []\n",
    "    for l in range(1, 4): #Used to be 6\n",
    "        for x in range(2**(l+3)):\n",
    "            cols = prng.permutation(seed_db.columns[:-1])\n",
    "            db_groups = seed_db.groupby(list(cols[:l])).groups\n",
    "            idxs = db_groups[list(db_groups)[prng.randint(len(db_groups))]]\n",
    "            L = idxs.size\n",
    "            L = min(L, 5000)\n",
    "            L = prng.randint(0.7*L, L)\n",
    "            idxs = prng.choice(idxs, L)\n",
    "            data = DB(seed_db.loc[idxs, cols[l:]], seed_db.loc[idxs, seed_db.columns[-1]], None, None, epsilon=eps, depth=l)\n",
    "            regs.append({name: alg.error(data) for name, alg in tree_algs.items()})\n",
    "            X.append(DBMetas()(data))\n",
    "            D.append(data)\n",
    "    #Large DBs    \n",
    "    for x in range(16):\n",
    "        cols = seed_db.columns[:-1]\n",
    "        L = len(seed_db)\n",
    "        L = min(L, 5000)\n",
    "        L = prng.randint(0.7*L, L)\n",
    "        new_db = seed_db.sample(L, random_state=prng)\n",
    "        data = DB(new_db.loc[:, cols], new_db.loc[:, seed_db.columns[-1]], None, None, epsilon=eps, depth=0)\n",
    "        regs.append({name: alg.error(data) for name, alg in tree_algs.items()})\n",
    "        X.append(DBMetas()(data))\n",
    "        D.append(data)\n",
    "    return (regs, X, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Does a similar thing as get_train_dbs, but makes fewer slices, and the slices are large\n",
    "because these are databases we want to test on (and we probably won't be using tiny dbs in real life).\n",
    "\"\"\"\n",
    "\n",
    "def get_test_dbs(seed_db, eps, prng):\n",
    "    cols = seed_db.columns[:-1]\n",
    "    y_col = seed_db.columns[-1]\n",
    "    L = len(seed_db)\n",
    "    L = min(L, int(5000/0.7))\n",
    "    L = prng.randint(0.7*L, L)\n",
    "    new_db = seed_db.sample(L, random_state=prng).reset_index(drop=True)\n",
    "    split = int(0.7*L)\n",
    "    md = min(len(cols), 4)\n",
    "    d = DB(new_db.loc[:split, cols], new_db.loc[:split, y_col], \\\n",
    "           new_db.loc[split:, cols], new_db.loc[split:, y_col], epsilon=eps, max_depth=md)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "directory = '/longterm/jimola/data_train.pkl'\n",
    "if rerun_gen_training_data:\n",
    "    prng=np.random.RandomState(12345)\n",
    "    eps_vals = np.array([0.05, 0.1, 0.25, 0.5, 0.8])\n",
    "    def get_test(db, prng):\n",
    "        dbs = []\n",
    "        for i in range(0, 3):\n",
    "            for e in eps_vals:\n",
    "                dbs.append(get_train_dbs(db, e, prng))\n",
    "        return dbs\n",
    "    data_train = [get_test(db, prng) for db in \\\n",
    "                  [nurs, default, loan, adult, lending]]\n",
    "    pickle.dump(data_train, open(directory, 'wb'))\n",
    "else:\n",
    "    #These dbs take up a ton of memory. They are not on the github repo but they are in a directory on Matt's machine\n",
    "    data_train = pickle.load(data_train, open(directory, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains a choicemaker\n",
    "\n",
    "Parameters:\n",
    "info: list of (regrets, metafeatures, db) tuples. \n",
    "            db is actually not needed; could just be a metafeature list.\n",
    "\"\"\"\n",
    "def get_cm(info):\n",
    "    regrets, X, datas = zip(*info)\n",
    "    regrets = pd.concat([pd.DataFrame(r) for r in regrets], ignore_index=True)\n",
    "    X = pd.concat([pd.DataFrame(r) for r in X], ignore_index=True)\n",
    "    return DTChoice(X, DBMetas(), tree_algs, regrets=regrets)\n",
    "\n",
    "if rerun_train_cms:\n",
    "    cms = [get_cm(o) for o in data_train]\n",
    "    mfs = [cm.X for cm in cms]\n",
    "    regs = [cm.regrets for cm in cms]\n",
    "    pickle.dump(mfs, open('decision_tree_metadata/data.pkl', 'wb'))\n",
    "    pickle.dump(regs, open('decision_tree_metadata/regrets.pkl', 'wb'))\n",
    "else:\n",
    "    mfs = pickle.load(open('decision_tree_metadata/data.pkl', 'rb'))\n",
    "    regs = pickle.load(open('decision_tree_metadata/regrets.pkl', 'rb'))\n",
    "    cms = [ DTChoice(mfs[i], DBMetas(), tree_algs, regrets=regs[i]) for i in range(len(mfs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A convenience method for taking training data in choicemakers and combining it into one choicemaker.\n",
    "Used in my experiments for leave-one-out cross validation.\n",
    "\n",
    "Parameters:\n",
    "cms: list of choicemakers.\n",
    "C, msl: parameters of the choicemaker's internal tree, but not super important as they can be set later.\n",
    "\"\"\"\n",
    "def combine_cms(cms, C=0, msl=1):\n",
    "    Xs = pd.concat([cm.X for cm in cms], ignore_index=True)\n",
    "    regs = pd.concat([cm.regrets for cm in cms], ignore_index=True)\n",
    "    dt = DTChoice(Xs, DBMetas(), tree_algs, regrets=regs, C=0)\n",
    "    dt.model = DecisionTreeClassifier(min_samples_leaf=msl, max_depth=3)\n",
    "    dt.retrain_model()\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tests a set of choicemakers on a test of databases and returns % classified correctly.\n",
    "Parameters:\n",
    "cm_list: list of choicemakers.\n",
    "dbs: list of test dbs.\n",
    "\"\"\"\n",
    "def get_results(dbs, cm_list):\n",
    "    budgets = [x.epsilon for x in dbs]\n",
    "    ans = []\n",
    "    for cm in cm_list:\n",
    "        dt = PDTree()\n",
    "        L = []\n",
    "        for t in dbs:\n",
    "            L.append( dt.fit_and_predict(t, cm) )\n",
    "            #print(dt.leaf.numruns)\n",
    "        for i in range(len(dbs)):\n",
    "            dbs[i].epsilon = budgets[i]\n",
    "        M = np.array([(L[i] == dbs[i].y_test).sum() / len(dbs[i].y_test) for i in range(len(dbs))])\n",
    "        ans.append(M)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reinitialize prng before the experiments so we can reproduce their exact runs\n",
    "prng = np.random.RandomState(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Format for the experiments:\n",
    "outsample_cm{i} is the choicemaker for all databases from which the test database are not generated from, \n",
    "        a sort of leave-one-out cross-validation.\n",
    "insample_cm{i} is the complement of big_cm{i}, so the same database is used for both training and\n",
    "        testing data. This is to serve as a comparison.\n",
    "I set the depth of the internal tree to 4,\n",
    "    and min. samples per leaf (see sklearn documentation) to 10, somewhat arbitrarily.\n",
    "I test using epsilon=0.25 and run 5 trials for each experiment on each database. This could certainly be increased\n",
    "as the error bars have high noise.\n",
    "\"\"\"\n",
    "epsilon = 0.25\n",
    "num_trials = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(i, db, msl=10, md=4):\n",
    "    insample_cm = cms[i]\n",
    "    insample_cm.model = DecisionTreeClassifier(min_samples_leaf=msl, max_depth=md)\n",
    "    insample_cm.retrain_model()\n",
    "    outsample_cm = combine_cms(cms[:i] + cms[(i+1):])\n",
    "    outsample_cm.model = DecisionTreeClassifier(min_samples_leaf=msl, max_depth=md)\n",
    "    outsample_cm.retrain_model()\n",
    "    if rerun_exps[i]:\n",
    "        res = get_results(db, [null_cm(), outsample_cm, insample_cm, fried_cm])\n",
    "        pickle.dump(res0, open('decision_tree_results/experiment%d.pkl' % i, 'wb'))\n",
    "    else:\n",
    "        res = pickle.load(open('decision_tree_results/experiment%d.pkl' % i, 'rb'))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nursdata = [get_test_dbs(nurs, epsilon, prng) for x in range(0, num_trials)]\n",
    "res0 = run_experiment(0, nursdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38088367, 0.53083703, 0.55432364, 0.5441282 ])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res0).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "defaultsdata = [get_test_dbs(default, epsilon, prng) for i in range(0, num_trials)]\n",
    "res1 = run_experiment(1, defaultsdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68098526, 0.7832593 , 0.77740296, 0.76155978])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(res1)).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "loandata = [get_test_dbs(loan, epsilon, prng) for i in range(num_trials)]\n",
    "res2 = run_experiment(2, loandata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55304248, 0.90349513, 0.90349513, 0.90349513])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res2).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "adultdata = [get_test_dbs(adult, epsilon, prng) for i in range(num_trials)]\n",
    "res3 = run_experiment(3, adultdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66016794, 0.75555059, 0.75555059, 0.7490822 ])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res3).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lendingdata = [get_test_dbs(lending, epsilon, prng) for x in range(num_trials)]\n",
    "res4 = run_experiment(4, lendingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60684178, 0.84203758, 0.81225911, 0.83877977])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res4).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.array([res0,res1,res2,res3,res4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E[dataset][algorithm][trial]\n",
    "stds = E.std(axis=2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = 1.0-E.mean(axis=2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'green', 'orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = [mpatches.Patch(color=c) for c in colors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 4 artists>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEiCAYAAAAWOs4eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xm4HFWZx/HvLzesYRMS2RIShICEZVATEMflqqiAw6ZsEZRNGVTADQZUBlkcRRwFHVAERARldVwCIqBIQFQgYU9ggLAmhiXIGiBAwjt/nHMrlU533869t7qz/D7P08+t9dRbp7v67TpVda4iAjMzM4BBnQ7AzMwWH04KZmZWcFIwM7OCk4KZmRWcFMzMrOCkYGZmBScF6zNJa0u6QdKLkr7X6XjaQdJKki6X9LykyzodTydJmi3pLZ2OA0DSBjmergEs80xJ/zlQ5S0pnBQqJOkRSa9JGloz/Q5JIWlUm+PplvRGPnhelHSfpAP7UeQhwNPAahHxlQEKc3G3B7A2sFZE7NnfwiSNkTRZ0rP59SdJY5osv7mka/Kyz0m6VdJOeV63pBn9jalVEbFKRDxURdmSNpF0maSncwK+S9KXG33pR8RjOZ55ef2Jkj7dnxgi4tCIOKk/ZSyJnBSq9zAwvmdE0pbASp0Lh5kRsQqwGnA0cHazL6F6lAwCRgL3RB+egJQ0eFHXWUyMBO6PiLmLumKDfZ5JSjRrAkOBCcDFTYq5HPgjKTG9GTgCeGFRY1mcSdoIuBmYDmwZEasDewJjgVXrLD/gn6WBPONY4kSEXxW9gEeAY4FJpWn/DXwdCGBUnrZCnv4Y8CRwJrBSnvcm4ApgFvBsHh5eKm8icBLwV+BF4BpgaIN4uoEZNdNmAXvk4XcCfwOeA+4Eumu28195O68AvwBeB14DZgPb5/04jfRFNzMPr1DeNikRPQFcUJr2H8BTwOPAbsBOwP3AM8DXSjFsA/w9x/c4cDqwfGl+AIcCD+S6OgNQaf5ngHtzPd0DvD1PXw/431wXDwNHNKi/E/L+vp73+WDSD6tjgUfzPpwPrJ6XH5VjOji/tzf08nkZDHweeLnB/KG5vDXqzBuS35c3cmyz83618p58jXTG9wiwb6nM80ifxT/mOrseGFlT3xuXlj0D+H1e9mZgo9KyHwbuA54HfpTL+nSD/fwF8Psm9bRQvZamDSZ9TucBc3I9nJ7Xe2vel2dyLHvV7OuPgSuBl0if5/OAb7ZyHC5Nr44HsDS/8kG2ff4AbgZ0kX79jGTBpHAa6RfimqRfQpcD387z1gI+Dqyc510G/La0jYnAg8AmpDOQicDJDeLpJicF0pfZ7qQvuE2B9YF/kr6QBwEfyuPDStt5DNg8H3jLlQ+avMyJwE2kX7DDSAnmpNK25wLfIX1RrVSadlwu7zP5oLsw7+vm+cB+Sy7jHaTENTh/CdwLfLG0/cgH6xrABrmsHfK8PYF/AOMAARvn92EQcGuOYXngLcBDwEca1OHxwC9K4wcB0/J6qwC/Bi7I80blmM4nfWmv1OSz8lyuizeAYxssI1LCu4KUPNdu9P4u4nvy/fyevI/0hbhpnn8e6Qv+vXn+D4Aba+q7nBSeISXuwcAvgYvzvKGks5mP5XlfIH3uGiWFJ4ADm9TVQvVamja49Hn9dGmdIaRj78Acw9tJiXDzUvzPA/+aPxMrsmBSaHocLk2vjgewNL+YnxSOBb4N7ED6pTI4f4BH5QP9JRb8VbUd8HCDMrcGni2NTyx/iQCfA65qsG436UvnuXwA3wHsk+cdTf4yKy1/NbB/aTsn1swvDpo8/iCwU2n8I8AjpW2/BqxYE88rQFceXzXXy7alZW4FdmuwP18EflMaD+DdpfFLgWNK+/KFOmVsCzxWM+2rwM8abPN4FkwK1wKfK41vSvrC60lcQU5qLXxehuT376NNlhlOOkN6ML+XNwCjS/VZmxR6e0/mAkNq6uw/S+/vxaV5q5B+gY8o1Xc5KZxTWnYn4P/y8KeAv5fmifQF3SgpvE5O5g3mL1Sv9J4U9gb+UlPOT4BvlOI/v9nnu9lxuDS9ltR23SXNBaSDd0PSr5uyYaRfH7dK6pkm0lkFklYGTiUllDfl+atK6op8UY30y6rHy6SDt5GZETG8zvSRwJ6Sdi5NWw64rjQ+vUm5kJorHi2NP5qn9ZgVEXNq1vlnaT9eyX+fLM1/hbw/kjYh/aodS6qzwaSkUdaoLkaQviBrjQTWk/RcaVoX8Jc6y9ZTb58Hk9r8e/RWbwBExEuSzgRmSdosIp6qs8wM4DAASSOAs0ifqe0WIb7ye/JsRLzUZH4Re0TMlvRMnl9vnxrV/QLLR0T0ckH8n8C6TeYvFFsLRgLb1rzPg0nHZq/ltXgcLhV8obkNIuJRUlv1TqTmhbKnSV98m0fEGvm1eqSLwQBfIf363DYiViOdykNKHANpOulMYY3Sa0hEnFzelV7KmEk6+HpskKe1un5vfgz8H+mX8WqktvBW62E6sFGD6Q/X7PeqEbFTi+XW2+e5LJjYFmW/B5ES3vq9LRgR00nt+Fs02U5v78mbJA1pMn9Ez4CkVUhNnOX5rXicdIbTU47K43X8idRU05tm9Vo7bzpwfc37vEpEfLbF8tp1HHack0L7HAx8oOZXGRHxBnA2cKqkNwNIWl/SR/Iiq5KSxnOS1gS+UVF8vwB2lvQRSV2SVsy3ODY7eGtdBBwraVi+Dfe4XO5AWZXUNj1b0luBz/ayfNk5wJGS3pHvntpY0kjgFuAFSUfnZxC6JG0haVyL5V4EfEnShvlL81vAJdHi3UmSPiTpbXm7q5HOhJ4lXS+pXfZNkk7IsQ/KdXwQ6ZoBpES0lqTVa+Lr7T05QdLykt4D/BupvbzHTpLeLWl50g0NN+dktCh+D2wpabd8p9DngXWaLP8N4F2SvitpnbzvG0v6haQ1Wtzmk6TrPD2uADaR9ElJy+XXOEmbtVheu47DjnNSaJOIeDAiJjeYfTTpYuVNkl4g/VLaNM87jXQh7WnSwX9VRfFNB3Yl/fqeRfpldRSL9hn5JjAZuAu4G7gtTxsoRwKfIF38PBu4pNUVI+Iy0l0pF+b1fwusmU/9dya1ET9MqudzgNUbFFXrXOY3Dz5MujB+eKtxkS6KX0S6yPkg6QL4DnWa2SBdkxlF+ny8AEwBXgUOyPv4f7msh/IzDOvR+3vyBCkJzSRdHD40l9PjQtIX4DOkC/37LsK+keN6mnSh/xRS09CYHNOrDZZ/kNQcNgqYKul50t1hk0nvXSt+AOyRn+f4YUS8SLoDah/Svj7B/JseWtGW43BxoHzRxMyWMZK6SRfN654NSjqPdOH62AHe7iDSrbD7RsR1vS1v7eUzBTOrXG6WXEPSCsy/FnRTL6tZBzgpmFk7bEdqHnua1Fy3W0S80nwV6wQ3H5mZWcFnCmZmVnBSMDOzwhL3RPPQoUNj1KhRnQ7DzGyJcuuttz4dEcN6W26JSwqjRo1i8uRGt/ubmVk9kh7tfSk3H5mZWYmTgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZWcFJok+7ubrq7uzsdhplZU04KZmZWcFIwM7OCk4KZmRWcFMzMrOCkYGZmBScFMzMrOCmYmVnBScHMzApOCmZmVnBSMDOzgpOCmZkVnBTMzKzgpGBmZoXBnQ6graROR9DZGCI6t20zWyL4TMHMzApOCmZmVnBSMDOzgpOCmZkVnBTMzKzgpGBmZoVKk4KkHSTdJ2mapGOaLLeHpJA0tsp4zMysucqSgqQu4AxgR2AMMF7SmDrLrQocAdxcVSxmZtaaKs8UtgGmRcRDEfEacDGwa53lTgJOAeZUGIuZmbWgyqSwPjC9ND4jTytIehswIiKuqDAOMzNrUZVJoV5/DkU/C5IGAacCX+m1IOkQSZMlTZ41a9YAhmhmZmVVJoUZwIjS+HBgZml8VWALYKKkR4B3AhPqXWyOiLMiYmxEjB02bFiFIZuZLduqTAqTgNGSNpS0PLAPMKFnZkQ8HxFDI2JURIwCbgJ2iYjJFcZkZmZNVNZLakTMlXQYcDXQBZwbEVMlnQhMjogJzUtYukzsdABmZi2otOvsiLgSuLJm2nENlu2uMhYzM+udn2g2M7OCk4KZmRWcFMzMrOCkYGZmBScFMzMrOCmYmVnBScHMzApOCmZmVnBSMDOzgpOCmZkVnBTMzKzgpGBmZgUnBTMzKzgpmJlZwUnBzMwKTgpmZlZwUjAzs4KTgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZWcFIwM7OCk4KZmRWcFMzMrOCkYGZmBScFMzMrOCmYmVnBScHMzApOCmZmVnBSMDOzgpOCmZkVnBTMzKzgpGBmZgUnBTMzK1SaFCTtIOk+SdMkHVNn/qGS7pZ0h6QbJY2pMh4zM2uusqQgqQs4A9gRGAOMr/Olf2FEbBkRWwOnAN+vKh4zM+tdlWcK2wDTIuKhiHgNuBjYtbxARLxQGh0CRIXxmJlZLwZXWPb6wPTS+Axg29qFJH0e+DKwPPCBegVJOgQ4BGCDDTYY8EDNzCyp8kxBdaYtdCYQEWdExEbA0cCx9QqKiLMiYmxEjB02bNgAh2lmZj2aJgVJgyRN6WPZM4ARpfHhwMwmy18M7NbHbZmZ2QBomhQi4g3gTkl9abOZBIyWtKGk5YF9gAnlBSSNLo1+FHigD9sxM7MB0so1hXWBqZJuAV7qmRgRuzRbKSLmSjoMuBroAs6NiKmSTgQmR8QE4DBJ2wOvA88C+/dxP8zMbAC0khRO6GvhEXElcGXNtONKw1/oa9lmZjbwek0KEXG9pLWBcXnSLRHxVLVhmZlZJ/R695GkvYBbgD2BvYCbJe1RdWBmZtZ+rTQffR0Y13N2IGkY8CfgV1UGZmZm7dfKcwqDapqL/tniemZmtoRp5UzhKklXAxfl8b2puXhsZmZLh1YuNB8l6WPAu0lPKZ8VEb+pPDIzM2u7pkkh93R6dURsD/y6PSGZmVmn9PZE8zzgZUmrtykeMzProFauKcwB7pb0RxZ8ovmIyqIyM7OOaCUp/D6/zMxsKdfKNYUPRcR+bYrHzMw6qJVrCsNyL6dmZsus7u5uuru7Ox1G5VppPnoE+KukCSx4TcH/T9nMbCnTSlKYmV+DgFWrDcfMzDqplYfXFuo6W1KV/9vZzCrQ0/QxceLEjsZhi7eG1xQk3VgavqBm9i2VRWRmZh3T7ELzkNLwFjXzVEEsZmbWYc2SQjQYrjduVqll5c4Ps05rdm1gDUm7kxLHGrlTPEhnCe72wsxsKdQsKVwP7FIa3rk074bKIjIzs45pmBQi4sB2BmJmZp3nW0vNbMlxYQfvcen5/5OdjOET1V/OdVIwaxOd0OGb9h5JfzoZR3zD96gs7pwUrGVaDG5E7mQM4e8zWwa0lBQkvQsYVV4+Is6vKCYzM+uQXpNCfpp5I+AOYF6eHICTgpnZUqaVM4WxwJgInzybmS3tmv4/hWwKsE7VgZiZWee1cqYwFLhH0i3Aqz0TI2KXxquYmdmSqJWkcHzVQZj1bmKnAzBbJrTy/xSub0cgZlYx91FgLej1moKkd0qaJGm2pNckzZP0QjuCMzOz9mql+eh0YB/gMtKdSJ8CRlcZlJnZ4mbisZ2OoD1aengtIqZJ6oqIecDPJP2t4rjMzKwDWkkKL0taHrhD0inA4yz4X9nMzGwp0cpzCp/Myx0GvASMAD5eZVBmZtYZvSaFiHiU9N/W1o2IEyLiyxExrZXCJe0g6T5J0yQdU2f+lyXdI+kuSddKGrnou2BmZgOllbuPdib1e3RVHt9a0oQW1usCzgB2BMYA4yWNqVnsdmBsRGwF/Ao4ZdHCNzOzgdRK89HxwDbAcwARcQepx9TebANMi4iHIuI14GJg1/ICEXFdRLycR28ChrcWtpmZVaGVpDA3Ip7vQ9nrA9NL4zPytEYOBv7Qh+2YmdkAaeXuoymSPgF0SRoNHAG0cktqvX+HUrenVUn7kZ6BeF+D+YcAhwBssMEGLWzazMz6opUzhcOBzUmd4V0EvAB8sYX1ZpDuVOoxHJhZu5Ck7YGvA7tExKu18wEi4qyIGBsRY4cNG9bCps3MrC9a6fvoZdKX9tcXsexJwGhJGwL/ID0V/YnyApLeBvwE2CEinlq4CDMza6eGSaG3O4x66zo7IuZKOgy4GugCzo2IqZJOBCZHxATgu8AqwGVK/3z3MXfJbWbWOc3OFLYjXSi+CLiZ+tcImoqIK4Era6YdVxreflHLNDOz6jRLCusAHwLGk5p9fg9cFBFT2xGYmZm1X8MLzRExLyKuioj9gXcC04CJkg5vW3RmZtZWTS80S1oB+CjpbGEU8EPg19WHZWZmndDsQvPPgS1ID5SdEBFT2haVmZl1RLMzhU+SekXdBDgi3x0E6YJzRMRqFcdmZmZt1jApREQrD7aZmdlSxF/8ZmZWcFIwM7OCk4KZmRWcFMzMrOCkYGZmBScFMzMrOCmYmVnBScHMzApOCmZmVnBSMDOzgpOCmZkVnBTMzKzgpGBmZgUnBTMzKzgpmJlZwUnBzMwKTgpmZlZwUjAzs4KTgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZWcFIwM7OCk4KZmRWcFMzMrOCkYGZmBScFMzMrOCmYmVmh0qQgaQdJ90maJumYOvPfK+k2SXMl7VFlLGZm1rvKkoKkLuAMYEdgDDBe0piaxR4DDgAurCoOMzNr3eAKy94GmBYRDwFIuhjYFbinZ4GIeCTPe6PCOMzMrEVVNh+tD0wvjc/I08zMbDFVZVJQnWnRp4KkQyRNljR51qxZ/QzLzMwaqTIpzABGlMaHAzP7UlBEnBURYyNi7LBhwwYkODMzW1iVSWESMFrShpKWB/YBJlS4PTMz66fKkkJEzAUOA64G7gUujYipkk6UtAuApHGSZgB7Aj+RNLWqeMzMrHdV3n1ERFwJXFkz7bjS8CRSs5KZmS0G/ESzmZkVnBTMzKzgpGBmZgUnBTMzKzgpmJlZwUnBzMwKTgpmZlZwUjAzs4KTgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZWcFIwM7OCk4KZmRWcFMzMrOCkYGZmBScFMzMrOCmYmVnBScHMzApOCmZmVnBSMDOzgpOCmZkVnBTMzKzgpGBmZgUnBTMzKzgpmJlZwUnBzMwKTgpmZlZwUjAzs4KTgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWaHSpCBpB0n3SZom6Zg681eQdEmef7OkUVXGY2ZmzVWWFCR1AWcAOwJjgPGSxtQsdjDwbERsDJwKfKeqeMzMrHdVnilsA0yLiIci4jXgYmDXmmV2BX6eh38FfFCSKozJzMyaGFxh2esD00vjM4BtGy0TEXMlPQ+sBTxdXkjSIcAheXS2pPsqibh6Q6nZt7Za8vNtR+tvya8+oNN1ePwSX4mdPYb37Vf9jWxloSqTQr3oow/LEBFnAWcNRFCdJGlyRIztdBxLKtdf/7kO+2dZqL8qm49mACNK48OBmY2WkTQYWB14psKYzMysiSqTwiRgtKQNJS0P7ANMqFlmArB/Ht4D+HNELHSmYGZm7VFZ81G+RnAYcDXQBZwbEVMlnQhMjogJwE+BCyRNI50h7FNVPIuJJb4JrMNcf/3nOuyfpb7+5B/mZmbWw080m5lZwUnBzMwKTgp9JCkkfa80fqSk43tZZ5d63X0sqyTN7sM6X+tvGUsD1918ktaRdLGkByXdI+lKSZu0OYZRkj5RGh8r6Yd5uFvSu9oZT384KfTdq8DHJA1tdYWImBARJ1cY07Lga70vYg0sdXWXe0D4DTAxIjaKiDGk/Vy7zaGMAoqkEBGTI+KIPNoNLFJSyLfod4STQt/NJd2J8KXaGZJ2zh383S7pT5LWztMPkHS6pNUlPSJpUJ6+sqTpkpaTtJGkqyTdKukvkt7a3t1qLyXflTRF0t2S9s7T15V0g6Q78rz3SDoZWClP+2Wdso6SNEnSXZJOaPvOtJnrDoD3A69HxJk9EyLiDuDGBnXTLel6SZdKul/SyZL2lXRLXm6jvNx5ks7Mx+D9kv4tT+/K5fbU1b/nzZ4MvCfX75fydq5Q6uTzUOBLed57JI2UdG1e/1pJG5S2+X1J19HJfuAiwq8+vIDZwGrAI6SH7o4Ejs/z3sT8O7s+DXwvDx8AnJ6Hfwe8Pw/vDZyTh68FRufhbUnPbnR8fyusw48DfyTdtrw28BiwLvAV4Ot5uS5g1Z51asvIfz9MStIi/di5Anhvp/fRdVd5PRwBnFpneqO66Qaey8MrAP8ATsjrfAE4LQ+fB1yV62M06UHbFUnd7Rybl1kBmAxsmMu9orT9Yhw4HjiyNO9yYP88fBDw29I2rwC6OlmnHTtFWRpExAuSzid9MF8pzRoOXCJpXWB54OE6q19CSgbXkZ7P+JGkVUinmZdpfkc7K1QU/uLi3cBFETEPeFLS9cA40sOP50pajnTQ3NFLOR/Or9vz+Cqkg/mGasJeLLjuGmtUNy8AkyLicQBJDwLX5HXuJp159Lg0It4AHpD0EPBWUj1tJWmPvMzqpLp6bRFi2w74WB6+ADilNO+yHHPHuPmo/04jdQE+pDTtf0hnBFsC/076hVFrArCjpDWBdwB/Jr0fz0XE1qXXZtWG33F1e/iKiBuA95J+yV0g6VMtlPPtUr1tHBE/HeBYFzeuO5hKOn5qNes57tXS8Bul8TdY8IHe2oe4Ipd7eKmuNoyIa+if8nZe6mdZ/eak0E8R8QxwKSkx9FiddEDC/G48atebDdwC/IB0mjkvIl4AHpa0JxRtxv9SWfCLhxuAvXNb7TDSl9ktkkYCT0XE2aQn39+el389/wKudTVwUD7bQtL6kt7chvg7qfK6y23e61e+J333Z2AFSZ/pmSBpHPAsdepmEcveU9KgfJ3hLcB9pLr6bE89StpE0hDgRWDVBuXUzvsb83tv2Be4cRHjqpSbjwbG94DDSuPHk5qA/gHcRGpzrOcS4DJS+2OPfYEfSzoWWI70fyjuHOB4O07p7opXSXeObEfaxwD+IyKekLQ/cJSk10nt5z2/ds8C7pJ0W0Ts21NeRFwjaTPg77npbTawH/BUu/apXdpVd5KeBjZmMe6kMiJC0u7AaUq3e88hXef7IqkZrLZuFuXGjfuA60nXJA6NiDmSziHdaXSbUmXNAnYD7gLmSrqTdG3g9lI5lwO/krQrcDipuflcSUfl9Q/sy75Xxd1cWEfkM6CzI2KbTseypGlX3UnaAjgoIr5c5XYWR5LOI53B/6rTsbSbm4+s7SQdClwEHNvpWJY07ay7iJiyLCaEZZ3PFMzMrOAzBRtwSg/mtfykt6RNJU3MD/fcK6nS7ol7Hiyqchs12xsu6XeSHlDqiuEHSv9jpLf1FvkJZEl75jq8rmb6IEk/1PyHuSZJanSta0As6udgALe7u1I3NG/N46MkTRnA8s+RNCYPf600fUC30ylOCrY4+CHpAaSeW3D/p9MBDZR8MfLXpOcFRgObkC6A/lcLq/elW4qDgc9FxPtrpu8NrAdslW+V3p30ENfSaDzpjp4B//8skroi4tMRcU+etNR1HeKkYJXJv5zulXS2pKmSrpG0Up1F1yU9MQpARNxdWv8vkm7Lr3fl6f3qqqAmxiGSzs2/nG/Pd4gMpA8AcyLiZ3nf5pG6RjlIqXuTAySdXornirx/vXVLMT7v6xRJ38nTjiM9tHWmpO/WrLIu8Hh+GIuImBERz+b1fixpcn6PTiht4xFJ35L09zz/7ZKuzmc7h+ZlupW61PiNUmd0Zyp331IT7375/blD0k8kdfWnUhtRuq32X0nJcaGkkOv8UqUuJi5R6o5mbJ63UJ3m6bMlnSjpZmC7fFY7tsF71FXv857XOTXX1b2Sxkn6dT57/GYVddFnnXyc2q+l80W6JXAo6da9ucDWefqlwH51lj8QeB74A+kLc408fWVgxTw8mvQf+6D/XRV0M78Lgm/1xASsAdwPDBnAumjUDcPtwFaUuj7J068AuvPw7AZlrkfqtmEY6bbyPwO75XkTgbF11hme35c7SLdQv600b838tyuvv1XpffxsHj6VdNvlqnm7T5Xeizmk+/i7SF1L7FHzOdiMdFvmcnn6j4BPVfTZ2w/4aR7+G+kZjVHAlDztSOAneXiL/Pkc20udBrBXaRtFHZffI5p83vM63yl9Rmcy//M7A1ir08dtz8tnCla1h2N+Nwu3kg6cBUT6Fb0Z85/ZuEnSCqTnNM6WdHeeN6a02qSIeDwiXgVquyoob+PSiHgjIh4AeroqKPswcIykO0gH7orABn3a0/rEwk/GNpveinGkXkFnRcRc4Jekh7MaiogZwKbAV0lP7l4r6YN59l6SbiMlqs1ZsJ57/q/63cDNEfFiRMwC5khaI8+7JSIeinQWdBHpbKXsg6Snjiflev4gKYlUYTzp2R7y3/E189/dMz8ippASHTSv03nA/7a4/Waf93JdTi19fh8CRrRYfuX88JpVrdylwDygXvMRETETOJf0UM8U0q+4nYEngX8h/dqf06DcRe2qoEzAxyPivl73pG+mkjpnm79BaTXSl8CDzN+3HvW6RKnVrAuHhvIX0B+AP0h6EthNqU+fI4FxEfGs0v355RjK9Vpb5z313Eod/zwivtqXuFslaS1Sc90WkoJ05hKkM5NyLHVXb1L0nGi9P6Jmn/dW6rLjfKZgA0L96A5B0g6a323AOsBapCah1ZnfDv5J0kG+qOp1VVB2NXB4viCMpLf1ZR+auBZYWbn/odyW/j3gvIh4mdTEsnWOcQRQfiCtUbcUNwPvkzQ0lzee9ORtQ/l6wHp5eBCp6epRUk+/LwHPK3XxvmMf9nEbSRvmcvdm4W4brgX20PyuM9ZU6opjoO0BnB8RIyNiVESMIHVGOby0zI3AXjmOMcCWefoi12nW6D1aYjkpWL/lL4P+dIfwYWCKUhcBVwNHRcQTpF94+0u6iXTXTl86C+vpquAP5K4KauafRGqmuiufoZzUx32oK1Ij8u6k5PQA6ZrFHObftfJX0hfX3cB/A7eVVu/plmKBC82Revj8KqmH3TvuuRd+AAABmklEQVSB2yLid72E8mbg8ryPd5Havk+PiDtJzUZTSWdqf+3Dbv6d9P8EpuR9+U1NvPeQHra7RtJdpOsO6/ZhO70ZX7ttUrNP+Q6hHwHDchxHk+ri+T7WKTR4j5ZkfnjN+k2LaXcIWoa7KmgXSd2k/xWw0J1di6N8FrBcpH6MNiKdxWwSEYvS9fVSbbFpx7IlV75gt1glBLMGVgauy00+It1d5YRQ4jMFMzMr+JqCmZkVnBTMzKzgpGBmZgUnBVvmyL1omjXkpGDLIveiadaAk4ItU9yLpllzTgq2rNkNuCoi7geekfT2mvmfA56NiK1ITze/AyB3EfEdUt86WwPjJO2W1xlC6oVz24gouniIiGOAVyL9n4h98+TRwBkRsTmpp9dyv0ivRcR7gTOB3wGfJ/UBdUDu18esck4KtqxxL5pmTfiJZltmuBdNs975TMGWJe5F06wXTgq2LHEvmma9cN9HZiXuRdOWdW6nNFuQe9G0ZZrPFMzMrOBrCmZmVnBSMDOzgpOCmZkVnBTMzKzgpGBmZgUnBTMzK/w/d++9tilQ61cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc0ed18f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axis = plt.subplots()\n",
    "axis.set_xticks([0,1,2,3])\n",
    "axis.set_xticklabels(['Naive','Jostle\\n,In Sample','Jostle,\\nOut of Sample','Competitor\\nAlgorithm'])\n",
    "axis.set_xlabel('Algorithm')\n",
    "axis.set_ylabel('Mean Error')\n",
    "#axis.legend(handles=patches, labels=['Alg1', 'Alg2', 'Jostle'])\n",
    "axis.set_title('Mean Performance for 3 Stopping Criteria')\n",
    "axis.bar(range(4), errors, color=colors, yerr=stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
