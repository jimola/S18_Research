{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from log_regression import test, DPLogisticRegression\n",
    "\n",
    "test(2.0, 2.0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set\n",
    "#def gen_binary_data(domain, nrow, seed):\n",
    "ncol = 7\n",
    "nrow = 1000\n",
    "seed=12345\n",
    "y_ratio=0.4\n",
    "def gen_data(low, high, ncol, nrow, y_ratio, seed=12345):\n",
    "    \"\"\"Generates an array containing a binary output and inputs drawn \n",
    "    from Gaussians. The output is the last column of the array\n",
    "    and the inputs are the other columns. The inputs are conditionally\n",
    "    independent of each other given the output. Thus, input at column i\n",
    "    for output value j are drawn from a normal with mean mu_ij and \n",
    "    sigma_ij. Furthermore, we force sigma_ij = sigma_i with no dependence\n",
    "    on j because this assumption allows us to derive logistic regression\n",
    "    as the best fitting algorithm. We draw sigma_i and mu_ij randomly.\n",
    "    We ensure sigma_i is at most one-quarter of high-low to ensure the\n",
    "    Gaussian will mostly fit in the [low, high] interval.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    low: lower bound on an input value\n",
    "    \n",
    "    high: upper bound on an input value\n",
    "    \n",
    "    ncol: number of inputs of the dataset\n",
    "    \n",
    "    nrow: number of rows in the dataset\n",
    "    \n",
    "    y_ratio: fraction of rows that take value 0 on the output column\n",
    "    \n",
    "    seed: seed value to use. Default: 12345\n",
    "    \"\"\"\n",
    "    prng = np.random.RandomState(seed)\n",
    "    sigmas = prng.uniform(0, (high-low)/6, ncol)\n",
    "    s1 = int(y_ratio*nrow)\n",
    "    s2 = nrow-s1\n",
    "    def gen_col(sigma, sz):\n",
    "        mu = prng.uniform(low+3*sigma, high-3*sigma)\n",
    "        ans = prng.normal(mu, sigma, sz)\n",
    "        c = (ans < low).sum()\n",
    "        while(c > 0):\n",
    "            ans[ans < low] = prng.normal(mu, sigma, c)\n",
    "            c = (ans < low).sum()\n",
    "        c = (ans > high).sum()\n",
    "        while(c > 0):\n",
    "            ans[ans > high] = prng.normal(mu, sigma, c)\n",
    "            c = (ans > high).sum()\n",
    "        return ans\n",
    "    P1 = np.array([gen_col(s, s1) for s in sigmas] + [np.zeros(s1)]).T\n",
    "    P2 = np.array([gen_col(s, s2) for s in sigmas] + [np.ones(s2)]).T\n",
    "    A = np.concatenate((P1, P2))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=.5\n",
    "low=0\n",
    "high=1\n",
    "ncol=7\n",
    "nrow=100\n",
    "pct=0.4\n",
    "C=1\n",
    "def gen_test(epsilon, ncol, nrow, pct=0.5, reps=10, low=0, high=5, seed=12345):\n",
    "    G = gen_data(low, high, ncol, 2*nrow, pct, seed)\n",
    "    X = G[:, 0:ncol]\n",
    "    y = G[:, ncol]\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5)\n",
    "    K = high*np.sqrt(ncol)\n",
    "    ans = 0\n",
    "    for x in range(0, reps):\n",
    "        plogit = DPLogisticRegression(epsilon, K, C, fit_intercept=True)\n",
    "        plogit = plogit.fit(X_train, y_train)\n",
    "        ans += plogit.score(X_test, y_test)\n",
    "    return ans/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = gen_data(low, high, ncol, 2*nrow, pct, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_test(2, 2, 1000, seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange2 = [2,7,70,170,270,400,700]\n",
    "ys2 = [gen_test(2, x, 1000) for x in xrange2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xrange2, ys2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange3 = [2,7,70,170,270,400,700]\n",
    "ys3 = [gen_test(2, x, 1000) for x in xrange3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xrange3, ys3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = gen_data(low, high, 2, 1000, pct, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = D[:, 1:2]\n",
    "y = D[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.around(1/(1+np.exp(X_test-0.5))).flatten() == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression(penalty='l2', C=1, dual=False, tol=1e-4, fit_intercept=True, class_weight=None, solver='liblinear')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(X_train, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(X[y == 1, 0], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(X[:, 0], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plogit = DPLogisticRegression(2, 1, C)\n",
    "plogit = plogit.fit(X_train, y_train)\n",
    "plogit.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plogit.logit.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_test(2, 2, 1000, seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sz in np.arange(200, 6000, 500):\n",
    "    ans = 0\n",
    "    G = gen_data(low, high, ncol, nrow, 0.4)\n",
    "    X = G[:, 0:ncol]\n",
    "    y = G[:, ncol]\n",
    "    K = high*np.sqrt(ncol)\n",
    "    plogit = DPLogisticRegression(epsilon, K, C)\n",
    "    plogit = plogit.fit(X, y)\n",
    "    plogit.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(5, C, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tset = []\n",
    "\n",
    "for c in [2, 7, 20]:\n",
    "    for r in [20, 100, 150, 300, 1000, 3000]:\n",
    "        for ratio in [0.3, 0.5, 0.7]:\n",
    "            G = gen_data(low=0, high=1, ncol=c, nrow=2*r, y_ratio=ratio, seed=12345)\n",
    "            X = G[:, 0:c]\n",
    "            y = G[:, c]\n",
    "            X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5)\n",
    "            tset.append(((X_train, y_train), (X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('log_regression.py').read())\n",
    "#alg_list\n",
    "class DP:\n",
    "    def __init__(self, C):\n",
    "        self.name = str(C)\n",
    "        self.epsilon=0.1\n",
    "        self.model = DPLogisticRegression(self.epsilon, C=C, K=1.02, fit_intercept=True)\n",
    "    def error(self, db):\n",
    "        self.model = self.model.fit(*(db[0]))\n",
    "        return -self.model.score(*(db[1]))\n",
    "    \n",
    "#alg_list = [DPLogisticRegression(0.1, C=x, fit_intercept=True) for x in [0.5, 1, 1.5, 2]]\n",
    "alg_list = [DP(C=x) for x in [0.5, 1, 1.5, 2]]\n",
    "train_set = tset\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfs argument\n",
    "class DBMetafeatures:\n",
    "    def __init__(self):\n",
    "        self.sens = {'nrow': 0, 'ncol': 0}\n",
    "    def eval(self, dataset):\n",
    "        X_train, y_train = dataset[0]\n",
    "        return pd.DataFrame({'nrow': X_train.shape[0], \n",
    "                             'ncol': X_train.shape[1]}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "class DTreeNode:\n",
    "    def __init__(self, md, qf):\n",
    "        self.max_depth = md\n",
    "        self.quality_func = qf\n",
    "    def leaf(self, y):\n",
    "        bests = y.columns[np.argmin(np.array(y), axis=1)]\n",
    "        freq_table = pd.value_counts(bests)\n",
    "        self.pred = freq_table.idxmax()\n",
    "        return self\n",
    "    def train(self, X, y):\n",
    "        if(len(X.columns) == 0 or self.max_depth == 0):\n",
    "            return self.leaf(y)\n",
    "        cur_score = self.quality_func(y)\n",
    "        best_col = ''\n",
    "        q_min = cur_score\n",
    "        for col in X:\n",
    "            x = X[col]\n",
    "            if(isinstance(x.dtype, CategoricalDtype)):\n",
    "                sizes = np.array([(x==c).sum() for c in x.cat.categories]) / len(x)\n",
    "                scores = np.array([self.quality_func(y[x==c]) for c in x.cat.categories])\n",
    "                qs = (sizes*scores).sum()\n",
    "                if(qs < q_min):\n",
    "                    q_min = qs\n",
    "                    best_col = (col, )\n",
    "            else:\n",
    "                for elem in np.random.choice(x, min(len(x), 50), replace=False):\n",
    "                    less = y[x < elem]\n",
    "                    geq = y[x >= elem]\n",
    "                    qs = (len(less)*self.quality_func(less) +\n",
    "                            len(geq)*self.quality_func(geq)) / len(x)\n",
    "                    if(qs < q_min):\n",
    "                        q_min = qs\n",
    "                        best_col = (col, elem)\n",
    "        if(q_min >= cur_score):\n",
    "            return self.leaf(y)\n",
    "        self.best_col = best_col\n",
    "        x = X[best_col[0]]\n",
    "        if(len(best_col) == 1):\n",
    "            self.children = dict([(c, DTreeNode(self.max_depth-1,\n",
    "                self.quality_func).train(X[x==c], y[x==c]))\n",
    "                             for c in x.cat.categories])\n",
    "        else:\n",
    "            e = best_col[1]\n",
    "            self.children = [\n",
    "                    DTreeNode(self.max_depth-1, self.quality_func).train(X[x<e], y[x<e]),\n",
    "                    DTreeNode(self.max_depth-1, self.quality_func).train(X[x>=e], y[x>=e])]\n",
    "        return self\n",
    "\n",
    "    def get_pred(self, x, budget, sens):\n",
    "        if(hasattr(self, 'pred')):\n",
    "            return self.pred, 0\n",
    "        col = self.best_col[0]\n",
    "        if(len(self.best_col) == 1):\n",
    "            return self.children[x[col]].get_pred(x, budget, sens)\n",
    "        split = self.best_col[1]\n",
    "        S = sens[col]\n",
    "        val = x.loc[0, col]\n",
    "        if(budget > 0):\n",
    "            val += np.random.laplace(0, S/budget)\n",
    "        if(val < split):\n",
    "            pred, used = self.children[0].get_pred(x, budget, sens)\n",
    "        else:\n",
    "            pred, used = self.children[1].get_pred(x, budget, sens)\n",
    "        return pred, used+budget\n",
    "    \n",
    "class DTree:\n",
    "    def __init__(self, max_depth, qf):\n",
    "        self.max_depth = max_depth\n",
    "        self.quality_func = qf\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        md = min(self.max_depth, X.shape[1])\n",
    "        self.dtree = DTreeNode(md, self.quality_func).train(X, y)\n",
    "        return\n",
    "    def predict(self, x, budget=0, sens=None):\n",
    "        if(len(x) == 1):\n",
    "            B = budget / len(sens)\n",
    "            return self.dtree.get_pred(x, B, sens)\n",
    "        else:\n",
    "            preds = []\n",
    "            for i in x.index:\n",
    "                row = x.loc[i, :]\n",
    "                preds.append(self.dtree.get_pred(row))\n",
    "            return np.array(preds)\n",
    "    def score(self, X, y):\n",
    "        preds = np.array(self.predict(X, budget, sens))\n",
    "        return (preds == y).sum()\n",
    "\n",
    "def gini_cnts(cnts):\n",
    "    probs = cnts / cnts.sum()\n",
    "    return 1-(probs*probs).sum()\n",
    "def gini(col):\n",
    "    cnts = pd.value_counts(col)\n",
    "    return gini_cnts(cnts)\n",
    "\n",
    "def group_gini(regrets, theta=1.0):\n",
    "    y = regrets.columns[np.argmin(np.array(regrets), axis=1)]\n",
    "    mean_regrets = regrets.mean(axis='index')\n",
    "    mean_regrets.sort_values(inplace=True)\n",
    "    last_idx = mean_regrets.index[0]\n",
    "    num_in_group = 0\n",
    "    cnts = []\n",
    "    for i in mean_regrets.index:\n",
    "        if(mean_regrets[i] - mean_regrets[last_idx] > theta):\n",
    "            last_idx = i\n",
    "            cnts.append(num_in_group)\n",
    "            num_in_group = (y == i).sum()\n",
    "        else:\n",
    "            num_in_group += (y == i).sum()\n",
    "    if(num_in_group  > 0):\n",
    "        cnts.append(num_in_group)\n",
    "    cnts = np.array(cnts)\n",
    "    return gini_cnts(cnts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exec(open('ChoiceMaker.py').read())\n",
    "cm = ChoiceMaker.create_regret_based(train_set, alg_list, DTree(2, group_gini), DBMetafeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = []\n",
    "for c in [7]:\n",
    "    for r in [20, 100]:\n",
    "        for ratio in [0.5]:\n",
    "            G = gen_data(low=0, high=1, ncol=c, nrow=2*r, y_ratio=ratio, seed=12345)\n",
    "            X = G[:, 0:c]\n",
    "            y = G[:, c]\n",
    "            X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5)\n",
    "            test_set.append(((X_train, y_train), (X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cm.mkChoice(t) for t in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
