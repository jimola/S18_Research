

Experiment list:

Naive Bayes (NaiveBayes.ipynb)
Train a naive Bayes classifier selecting which private histogram algorithm to
use at different computations. Try to minimize the error of the classifier.

Goal: Show that a ChoiceMaker can do what the state-of-the-art (Pythia) 
does, but automated.

Comparison: Pythia paper has done this experiment. They provide algorithm
implementations, training dbs, and algorithm errors. They don't provide their
code for Naive Bayes, so I wrote the implementation with ChoiceMaker. They also
don't provide their testing dbs other than names.

They implement some "optimizations" that the ChoiceMaker doesn't have,
and the ChoiceMaker has some features they don't have, so there is some
disparity in our methods. Despite this, I expect similar choicemaking ability
measured in terms of mean error.

Current Results: Our training data seems to be the same as theirs. 
The algorithms appear to be producing the same resuts on the training dbs.
However, on the testing dbs, the errors I get are different, precluding any
comparision of choicemaking ability with Pythia. Our ChoiceMaker doesn't 
perform super well here from a simple regret-based comparison.

Concerns: They said in their email that their experiment wasn't designed very well; do I
even bother comparing to Pythia?
I'm not sure if I can implement the Pythia optimizations as they are kind of
ad hoc, and would defeat the purpose of the ChoiceMaker.


Logistic Regression (LogRegChoice.ipynb)
Perform a logistic regression selecting which hyperparameter to use.

Goal: See how a ChoiceMaker performs on "easier" DP problems where a
probabilistic bound can be derived.

Comparison: Differentially private ERM. We implement private logistic
regression, the ERM method, and a ChoiceMaker.

Current Results: This experiment is actually quite good. You can see the graph
in our paper---there is a definite area where a ChoiceMaker actually beats ERM,
and ChoiceMaker is never actually bad.


Decision Tree (DecisionTree.ipynb)
Train a Decision Tree classifier, selecting when it is time to stop branching to
avoid overfitting.

Goal: See how a ChoiceMaker performs when applied to differential privacy 

Comparison: We compare against a naive way of making a decision tree algorithm
private, as well as another method described in a sketchy paper. Everything was
implemented by me.

Current Results: The Choicemaker seems to be competitive with the two other methods
sometimes. We definitely need more data supporting this claim for a final submission.

Concerns: It takes a really long time to run the DTree algorithms because Python
is slow, so I don't have a ton of result data. Furthermore, I am concerned about 
the reproducibility of the results. I may have to train on more databases which
would take a long time or think of a way to simplify this whole experiment.
